{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE should use percision score since we care about mostly identifying who has pneumonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import average \n",
    "from keras import Input, Model\n",
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.io import imshow\n",
    "import seaborn as sns\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_images = []\n",
    "healthy_images = []\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "images = glob.glob(\"chest_xray/test/NORMAL/*\")\n",
    "for image in images:\n",
    "    im = cv2.imread(image,0)\n",
    "    im = cv2.resize(im,(200,200))\n",
    "    im = im.flatten()/255 -.5\n",
    "    healthy_images.append(im)\n",
    "images = glob.glob(\"chest_xray/test/PNEUMONIA/*\")\n",
    "for image in images:\n",
    "    im = cv2.imread(image,0)\n",
    "    im = cv2.resize(im,(200,200))\n",
    "    im = im.flatten()/255 -.5\n",
    "    pneumonia_images.append(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets put them together with y values\n",
    "healthy_images\n",
    "b = np.zeros((len(healthy_images),1))\n",
    "a = np.ones((len(pneumonia_images),1))\n",
    "healthy_images = np.hstack((healthy_images, b))\n",
    "pneumonia_images = np.hstack((pneumonia_images, a))\n",
    "images = np.vstack([healthy_images, pneumonia_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = images[:,-1]\n",
    "X = images[:,:-1]\n",
    "\n",
    "# folding below\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "img_wh = 200\n",
    "y_test_ohe = keras.utils.to_categorical(y_test, 2)\n",
    "y_train_ohe = keras.utils.to_categorical(y_train, 2)\n",
    "X_train_img = np.expand_dims(X_train.reshape((-1,img_wh,img_wh)), axis=3)\n",
    "X_test_img = np.expand_dims(X_test.reshape((-1,img_wh,img_wh)), axis=3)\n",
    "folds = StratifiedKFold(n_splits=5,random_state=1).split(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this is expansion on the dataset. This is a slower way to do it. When we use a keras generator we call .fit on a python generator\n",
    "#this will yield batches\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False, #do we want to make it 0 mean\n",
    "    featurewise_std_normalization=False, #do we take the whole batch and make it 0 mean, no\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=5, # used, Int. Degree range for random rotations. Randomly rotate images 5 degrees \n",
    "    width_shift_range=0.1, # used, Float (fraction of total width). Range for random horizontal shifts. \n",
    "    height_shift_range=0.1, # used,  Float (fraction of total height). Range for random vertical shifts.\n",
    "    shear_range=0., # Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False, \n",
    "    rescale=None) #this generator will esentially run forever. This will manipulate our data, will give us different datasets every time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 187, 187, 32)      6304      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 187, 187, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 93, 93, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 87, 87, 64)        100416    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 87, 87, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 41, 41, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 41, 41, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 39, 39, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 39, 39, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 37, 37, 128)       295040    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              169873408 \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2002      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 191,524,506\n",
      "Trainable params: 191,524,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "#Instantiate an empty model\n",
    "#get a bigger dataset\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=32, input_shape=(200,200,1), kernel_size=(14,14),  padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(7,7), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid', data_format=\"channels_last\"))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid', data_format=\"channels_last\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', data_format=\"channels_last\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid', data_format=\"channels_last\"))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Passing it to a Fully Connected layer\n",
    "model.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 3rd Fully Connected Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "from keras.callbacks import CSVLogger\n",
    "csv_logger = CSVLogger('alexNet_log.csv', append=True, separator=';')\n",
    "histories= []\n",
    "#datagen.fit(X_train)\n",
    "print(folds)\n",
    "for k, (train, test) in enumerate(folds):\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=[keras.metrics.Recall()])\n",
    "    print(\"new fold\")\n",
    "    datagen.fit(X_train_img)\n",
    "    histories.append(model.fit_generator(datagen.flow(X_train_img[train], y_train_ohe[train], batch_size=32),\n",
    "             steps_per_epoch=int(len(X_train)/2),\n",
    "             epochs=10, verbose=1,\n",
    "             validation_data=(X_test_img,y_test_ohe),\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', patience=2)]\n",
    "             ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'histories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4ce42bf1a356>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mold_histories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'histories' is not defined"
     ]
    }
   ],
   "source": [
    "old_histories = histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_histories[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_histories[0].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = old_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alexnet.txt\", \"w\") as f:\n",
    "    for history in test:\n",
    "        print(history.history, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Convolution Neural Network</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 200, 200, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 100, 100, 32) 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 100, 100, 32) 9248        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 50, 50, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 50, 50, 64)   2112        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 50, 50, 64)   36928       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 50, 50, 32)   2080        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 50, 50, 32)   0           conv2d_9[0][0]                   \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 50, 50, 32)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 32)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 20000)        0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 20000)        0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          5120256     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            514         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 2)            0           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,171,458\n",
      "Trainable params: 5,171,458\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ResNet style architecture\n",
    "# We will also use ReLU where approriate and drop out \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.layers import average, concatenate\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "l2_lambda = 0.000001\n",
    "input_holder = Input(shape=(img_wh, img_wh, 1))\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# start with a conv layer\n",
    "x = Conv2D(filters=32,\n",
    "               input_shape = (img_wh,img_wh,1),\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu', \n",
    "               data_format=\"channels_last\")(input_holder)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(x)\n",
    "\n",
    "x = Conv2D(filters=32,\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu', \n",
    "               data_format=\"channels_last\")(x)\n",
    "\n",
    "x_split = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(x)\n",
    "\n",
    "x = Conv2D(filters=64,\n",
    "               kernel_size=(1,1),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu', \n",
    "               data_format=\"channels_last\")(x_split)\n",
    "\n",
    "x = Conv2D(filters=64,\n",
    "               kernel_size=(3,3),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu', \n",
    "               data_format=\"channels_last\")(x)\n",
    "\n",
    "x = Conv2D(filters=32,\n",
    "               kernel_size=(1,1),\n",
    "               kernel_initializer='he_uniform', \n",
    "               kernel_regularizer=l2(l2_lambda),\n",
    "               padding='same', \n",
    "               activation='relu', \n",
    "               data_format=\"channels_last\")(x)\n",
    "\n",
    "# now add back in the split layer, x_split (residual added in)\n",
    "x = Add()([x, x_split])\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(256)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "resnet = Model(inputs=input_holder,outputs=x)\n",
    "\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New fold\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 29s 965ms/step - loss: 1.2026 - recall: 0.6537 - val_loss: 0.4304 - val_recall: 0.7840\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 29s 958ms/step - loss: 0.4132 - recall: 0.8095 - val_loss: 0.2777 - val_recall: 0.8720\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 28s 942ms/step - loss: 0.3633 - recall: 0.8245 - val_loss: 0.3009 - val_recall: 0.8560\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 29s 952ms/step - loss: 0.3803 - recall: 0.8245 - val_loss: 0.2606 - val_recall: 0.8960\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 29s 970ms/step - loss: 0.3518 - recall: 0.8408 - val_loss: 0.2103 - val_recall: 0.9040\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 28s 940ms/step - loss: 0.3020 - recall: 0.8742 - val_loss: 0.1819 - val_recall: 0.9200\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 29s 959ms/step - loss: 0.2692 - recall: 0.8820 - val_loss: 0.2394 - val_recall: 0.8720\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 29s 956ms/step - loss: 0.2574 - recall: 0.9026 - val_loss: 0.2838 - val_recall: 0.8560\n",
      "New fold\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 29s 971ms/step - loss: 0.3059 - recall_1: 0.8812 - val_loss: 0.2306 - val_recall_1: 0.8960\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 28s 939ms/step - loss: 0.3119 - recall_1: 0.8790 - val_loss: 0.1659 - val_recall_1: 0.9280\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 29s 956ms/step - loss: 0.2988 - recall_1: 0.8747 - val_loss: 0.1795 - val_recall_1: 0.9360\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 29s 962ms/step - loss: 0.2838 - recall_1: 0.8952 - val_loss: 0.1918 - val_recall_1: 0.9120\n",
      "New fold\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 29s 965ms/step - loss: 0.2530 - recall_2: 0.9017 - val_loss: 0.1635 - val_recall_2: 0.9120\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 29s 957ms/step - loss: 0.2089 - recall_2: 0.9186 - val_loss: 0.1525 - val_recall_2: 0.9440\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 29s 955ms/step - loss: 0.2140 - recall_2: 0.9093 - val_loss: 0.1885 - val_recall_2: 0.9280\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 29s 963ms/step - loss: 0.2353 - recall_2: 0.9082 - val_loss: 0.1717 - val_recall_2: 0.9120\n",
      "New fold\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 29s 969ms/step - loss: 0.2834 - recall_3: 0.8879 - val_loss: 0.1621 - val_recall_3: 0.9360\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 28s 941ms/step - loss: 0.2452 - recall_3: 0.9035 - val_loss: 0.1647 - val_recall_3: 0.9120\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 29s 957ms/step - loss: 0.2187 - recall_3: 0.9267 - val_loss: 0.1365 - val_recall_3: 0.9680\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 29s 962ms/step - loss: 0.2336 - recall_3: 0.9052 - val_loss: 0.3099 - val_recall_3: 0.8560\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.2501 - recall_3: 0.8980 - val_loss: 0.1671 - val_recall_3: 0.9600\n",
      "New fold\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 29s 951ms/step - loss: 0.2300 - recall_4: 0.9057 - val_loss: 0.1678 - val_recall_4: 0.9280\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 29s 962ms/step - loss: 0.1969 - recall_4: 0.9170 - val_loss: 0.1561 - val_recall_4: 0.9680\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 29s 960ms/step - loss: 0.1999 - recall_4: 0.9192 - val_loss: 0.1586 - val_recall_4: 0.9360\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 29s 960ms/step - loss: 0.1615 - recall_4: 0.9364 - val_loss: 0.1359 - val_recall_4: 0.9440\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 28s 947ms/step - loss: 0.1993 - recall_4: 0.9200 - val_loss: 0.1289 - val_recall_4: 0.9440\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 29s 958ms/step - loss: 0.1860 - recall_4: 0.9289 - val_loss: 0.1656 - val_recall_4: 0.9280\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 29s 966ms/step - loss: 0.1954 - recall_4: 0.9235 - val_loss: 0.1750 - val_recall_4: 0.9360\n",
      "Wall time: 13min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "csv_logger_resnet = CSVLogger('resnet_log.csv', append=True, separator=';')\n",
    "histories_resnet = []\n",
    "y_preds_resnet = []\n",
    "fpr_resnet = []\n",
    "tpr_resnet = []\n",
    "auc_resnet = []\n",
    "thresholds_resnet = []\n",
    "\n",
    "# the flow method yields batches of images indefinitely, with the given transformations\n",
    "for k, (train, test) in enumerate(folds):\n",
    "    resnet.compile(loss='categorical_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "                    optimizer='adam', # 'adadelta' 'rmsprop'\n",
    "                    metrics=[tensorflow.keras.metrics.Recall()])\n",
    "    print(\"New fold\")\n",
    "    datagen.fit(X_train_img)\n",
    "    \n",
    "    # the flow method yields batches of images indefinitely, with the given transofmrations\n",
    "    # size of X_train_img[train] is only 400, so def need more training data\n",
    "    histories_resnet.append(resnet.fit_generator(datagen.flow(X_train_img[train], y_train_ohe[train], batch_size=32), \n",
    "                              steps_per_epoch=30, # how many generators to go through per epoch\n",
    "                              epochs=10, verbose=1,\n",
    "                              validation_data=(X_test_img,y_test_ohe),\n",
    "                              callbacks=[EarlyStopping(monitor='val_loss', patience=2)]\n",
    "                             ))\n",
    "    ypred_keras = model.predict(X_test_img).ravel()\n",
    "    fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test_ohe.ravel(), ypred_keras)\n",
    "    auc_keras = auc(fpr_keras, tpr_keras)\n",
    "    fpr_resnet.append(fpr_keras)\n",
    "    tpr_resnet.append(tpr_keras)\n",
    "    auc_resnet.append(auc_keras)\n",
    "    y_preds_resnet.append(ypred_keras)\n",
    "    thresholds_resnet.append(thresholds_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4318137e-04, 9.9965680e-01],\n",
       "       [9.9641740e-01, 3.5825758e-03],\n",
       "       [9.9997294e-01, 2.7022694e-05],\n",
       "       [9.9956614e-01, 4.3383447e-04],\n",
       "       [1.0651717e-02, 9.8934829e-01],\n",
       "       [9.8200238e-01, 1.7997643e-02],\n",
       "       [9.0927624e-06, 9.9999094e-01],\n",
       "       [2.8139141e-01, 7.1860856e-01],\n",
       "       [9.8807240e-01, 1.1927672e-02],\n",
       "       [4.3601808e-01, 5.6398195e-01],\n",
       "       [9.9997354e-01, 2.6513188e-05],\n",
       "       [6.9778271e-02, 9.3022168e-01],\n",
       "       [3.5092947e-03, 9.9649066e-01],\n",
       "       [1.4078094e-03, 9.9859220e-01],\n",
       "       [9.9984193e-01, 1.5803924e-04],\n",
       "       [9.9961108e-01, 3.8896652e-04],\n",
       "       [9.5448732e-01, 4.5512684e-02],\n",
       "       [2.3957431e-02, 9.7604263e-01],\n",
       "       [3.2674730e-01, 6.7325276e-01],\n",
       "       [1.9632049e-02, 9.8036802e-01],\n",
       "       [7.9198956e-04, 9.9920803e-01],\n",
       "       [3.0417860e-04, 9.9969590e-01],\n",
       "       [3.6284140e-01, 6.3715863e-01],\n",
       "       [3.7662882e-02, 9.6233714e-01],\n",
       "       [2.2633778e-01, 7.7366221e-01],\n",
       "       [9.3651796e-03, 9.9063474e-01],\n",
       "       [5.7637697e-01, 4.2362303e-01],\n",
       "       [5.9358984e-02, 9.4064099e-01],\n",
       "       [2.2775518e-04, 9.9977225e-01],\n",
       "       [9.9809140e-01, 1.9085475e-03],\n",
       "       [1.8879189e-04, 9.9981123e-01],\n",
       "       [9.9122030e-01, 8.7797819e-03],\n",
       "       [1.0561127e-03, 9.9894387e-01],\n",
       "       [9.8241293e-01, 1.7587064e-02],\n",
       "       [2.7427498e-01, 7.2572505e-01],\n",
       "       [9.9868935e-01, 1.3106639e-03],\n",
       "       [8.0934697e-01, 1.9065297e-01],\n",
       "       [9.9999058e-01, 9.4265952e-06],\n",
       "       [2.0605279e-04, 9.9979395e-01],\n",
       "       [1.7389338e-02, 9.8261064e-01],\n",
       "       [4.5721197e-05, 9.9995422e-01],\n",
       "       [2.0987604e-02, 9.7901237e-01],\n",
       "       [9.9990797e-01, 9.1976784e-05],\n",
       "       [2.9388598e-01, 7.0611405e-01],\n",
       "       [2.0473400e-02, 9.7952658e-01],\n",
       "       [7.2784409e-02, 9.2721564e-01],\n",
       "       [9.9548560e-01, 4.5144190e-03],\n",
       "       [9.6949726e-01, 3.0502686e-02],\n",
       "       [9.9984062e-01, 1.5937473e-04],\n",
       "       [2.0816179e-02, 9.7918379e-01],\n",
       "       [9.9990249e-01, 9.7537602e-05],\n",
       "       [1.5697460e-01, 8.4302533e-01],\n",
       "       [1.3780934e-04, 9.9986219e-01],\n",
       "       [1.5512564e-04, 9.9984491e-01],\n",
       "       [3.8358915e-04, 9.9961638e-01],\n",
       "       [8.1020080e-06, 9.9999189e-01],\n",
       "       [7.8926557e-01, 2.1073441e-01],\n",
       "       [8.8906195e-04, 9.9911088e-01],\n",
       "       [1.9192310e-01, 8.0807686e-01],\n",
       "       [2.0009558e-01, 7.9990441e-01],\n",
       "       [1.2879645e-05, 9.9998713e-01],\n",
       "       [9.9732554e-01, 2.6744273e-03],\n",
       "       [4.3357007e-04, 9.9956638e-01],\n",
       "       [1.8025966e-01, 8.1974036e-01],\n",
       "       [4.5505934e-03, 9.9544936e-01],\n",
       "       [2.6515331e-03, 9.9734843e-01],\n",
       "       [9.5687670e-01, 4.3123331e-02],\n",
       "       [1.0096370e-05, 9.9998987e-01],\n",
       "       [9.9976212e-01, 2.3790824e-04],\n",
       "       [7.9199424e-05, 9.9992085e-01],\n",
       "       [8.2799536e-01, 1.7200461e-01],\n",
       "       [7.3860908e-01, 2.6139086e-01],\n",
       "       [1.9087556e-03, 9.9809128e-01],\n",
       "       [4.4254855e-05, 9.9995577e-01],\n",
       "       [3.2752167e-02, 9.6724784e-01],\n",
       "       [1.3907070e-03, 9.9860930e-01],\n",
       "       [1.1468937e-02, 9.8853099e-01],\n",
       "       [1.5921262e-03, 9.9840790e-01],\n",
       "       [7.6188022e-01, 2.3811981e-01],\n",
       "       [8.4877604e-01, 1.5122399e-01],\n",
       "       [1.8322019e-02, 9.8167795e-01],\n",
       "       [7.0499768e-06, 9.9999297e-01],\n",
       "       [4.3956711e-04, 9.9956042e-01],\n",
       "       [9.8308152e-01, 1.6918514e-02],\n",
       "       [9.8574489e-01, 1.4255161e-02],\n",
       "       [9.9992716e-01, 7.2858231e-05],\n",
       "       [4.7854925e-04, 9.9952149e-01],\n",
       "       [1.3244009e-01, 8.6755997e-01],\n",
       "       [8.3726745e-06, 9.9999166e-01],\n",
       "       [9.5742254e-04, 9.9904257e-01],\n",
       "       [5.3804595e-02, 9.4619542e-01],\n",
       "       [9.9912387e-01, 8.7618042e-04],\n",
       "       [9.2308575e-01, 7.6914310e-02],\n",
       "       [9.9869007e-01, 1.3099588e-03],\n",
       "       [9.4081195e-05, 9.9990594e-01],\n",
       "       [9.9780005e-01, 2.1999718e-03],\n",
       "       [6.2284327e-01, 3.7715676e-01],\n",
       "       [9.9992418e-01, 7.5836535e-05],\n",
       "       [9.1991001e-01, 8.0089957e-02],\n",
       "       [6.9872004e-01, 3.0127999e-01],\n",
       "       [1.8633369e-01, 8.1366628e-01],\n",
       "       [9.9863726e-01, 1.3627249e-03],\n",
       "       [8.5924538e-03, 9.9140757e-01],\n",
       "       [7.4213153e-01, 2.5786847e-01],\n",
       "       [2.0937225e-06, 9.9999785e-01],\n",
       "       [1.5149044e-02, 9.8485094e-01],\n",
       "       [1.0984347e-01, 8.9015651e-01],\n",
       "       [8.9077959e-03, 9.9109215e-01],\n",
       "       [9.9932170e-01, 6.7833171e-04],\n",
       "       [1.4340205e-02, 9.8565984e-01],\n",
       "       [9.9994552e-01, 5.4527885e-05],\n",
       "       [7.4038557e-03, 9.9259621e-01],\n",
       "       [9.8414892e-01, 1.5851073e-02],\n",
       "       [3.7047772e-05, 9.9996293e-01],\n",
       "       [1.5204136e-03, 9.9847955e-01],\n",
       "       [2.3635054e-01, 7.6364952e-01],\n",
       "       [9.9413222e-01, 5.8678160e-03],\n",
       "       [1.2741840e-01, 8.7258160e-01],\n",
       "       [7.4158514e-01, 2.5841480e-01],\n",
       "       [9.3089134e-01, 6.9108665e-02],\n",
       "       [9.4197607e-01, 5.8023915e-02],\n",
       "       [4.0509345e-05, 9.9995947e-01],\n",
       "       [5.3151243e-04, 9.9946851e-01],\n",
       "       [4.3150212e-04, 9.9956852e-01],\n",
       "       [8.4102370e-02, 9.1589761e-01]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_resnet = resnet.predict(X_test_img)\n",
    "y_pred_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.   , 0.008, 0.008, 0.016, 0.016, 0.024, 0.024, 0.04 , 0.04 ,\n",
      "       0.048, 0.048, 0.072, 0.072, 0.12 , 0.12 , 0.2  , 0.2  , 0.216,\n",
      "       0.216, 0.232, 0.232, 0.28 , 0.28 , 0.304, 0.304, 0.344, 0.344,\n",
      "       0.384, 0.384, 0.416, 0.416, 0.424, 0.424, 0.44 , 0.44 , 0.48 ,\n",
      "       0.48 , 0.488, 0.488, 0.496, 0.496, 0.504, 0.504, 0.56 , 0.56 ,\n",
      "       0.584, 0.584, 0.592, 0.592, 0.6  , 0.6  , 0.608, 0.608, 0.624,\n",
      "       0.624, 0.648, 0.648, 0.656, 0.656, 0.688, 0.688, 0.696, 0.696,\n",
      "       0.704, 0.704, 0.712, 0.712, 0.72 , 0.72 , 0.736, 0.736, 0.752,\n",
      "       0.752, 0.776, 0.776, 0.784, 0.784, 0.8  , 0.8  , 0.808, 0.808,\n",
      "       0.816, 0.816, 0.832, 0.832, 0.84 , 0.84 , 0.856, 0.856, 0.872,\n",
      "       0.872, 0.88 , 0.88 , 0.888, 0.888, 0.904, 0.904, 0.912, 0.912,\n",
      "       0.928, 0.928, 0.936, 0.936, 0.944, 0.944, 1.   , 1.   ]), array([0.   , 0.   , 0.056, 0.056, 0.064, 0.064, 0.072, 0.072, 0.088,\n",
      "       0.088, 0.096, 0.096, 0.112, 0.112, 0.12 , 0.12 , 0.128, 0.128,\n",
      "       0.144, 0.144, 0.16 , 0.16 , 0.168, 0.168, 0.184, 0.184, 0.192,\n",
      "       0.192, 0.2  , 0.2  , 0.216, 0.216, 0.224, 0.224, 0.248, 0.248,\n",
      "       0.264, 0.264, 0.28 , 0.28 , 0.288, 0.288, 0.296, 0.296, 0.304,\n",
      "       0.304, 0.312, 0.312, 0.344, 0.344, 0.352, 0.352, 0.376, 0.376,\n",
      "       0.392, 0.392, 0.4  , 0.4  , 0.408, 0.408, 0.416, 0.416, 0.44 ,\n",
      "       0.44 , 0.496, 0.496, 0.504, 0.504, 0.512, 0.512, 0.52 , 0.52 ,\n",
      "       0.56 , 0.56 , 0.576, 0.576, 0.584, 0.584, 0.616, 0.616, 0.656,\n",
      "       0.656, 0.696, 0.696, 0.72 , 0.72 , 0.768, 0.768, 0.784, 0.784,\n",
      "       0.8  , 0.8  , 0.88 , 0.88 , 0.928, 0.928, 0.952, 0.952, 0.96 ,\n",
      "       0.96 , 0.976, 0.976, 0.984, 0.984, 0.992, 0.992, 1.   ]))\n"
     ]
    }
   ],
   "source": [
    "print((fpr_resnet[0],tpr_resnet[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.plot(fprs[0], tprs[0], label='AlexNet (area = {:.3f})'.format(aucs[0]))\n",
    "# plt.plot(mlp_fprs[0], mlp_tprs[0], label='MLP (area = {:.3f})'.format(auc_rf))\n",
    "plt.plot(fpr_resnet[0], tpr_resnet[0], label='ResNet (area= {:.3f})'.format(auc_resnet[0]))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.7, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.plot(fprs[0], tprs[0], label='AlexNet (area = {:.3f})'.format(aucs[0]))\n",
    "# plt.plot(mlp_fprs[0], mlp_tprs[0], label='MLP (area = {:.3f})'.format(aucs[0]))\n",
    "plt.plot(fpr_resnet[0], tpr_resnet[0], label='ResNet (area= {:.3f})'.format(auc_resnet[0])) # Resnet doesn't show up in this area\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (zoomed in at top left)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.02325581, 0.76744186, 0.76744186, 0.81395349,\n",
       "       0.81395349, 0.8372093 , 0.8372093 , 0.88372093, 0.88372093,\n",
       "       0.90697674, 0.90697674, 0.97674419, 0.97674419, 1.        ,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test_ohe[:,0], y_pred_resnet[:,0])\n",
    "tpr_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "print(len(fpr_resnet[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.1890580232267256,\n",
       "  0.4130018817268925,\n",
       "  0.36155534984654936,\n",
       "  0.38294911746420873,\n",
       "  0.3513498618850789,\n",
       "  0.30026626635433296,\n",
       "  0.26613065613296644,\n",
       "  0.25800814178018344],\n",
       " 'recall': [0.65367967,\n",
       "  0.8095238,\n",
       "  0.8245033,\n",
       "  0.8245033,\n",
       "  0.84076434,\n",
       "  0.8741722,\n",
       "  0.88203466,\n",
       "  0.9025974],\n",
       " 'val_loss': [0.43037228286266327,\n",
       "  0.27765749394893646,\n",
       "  0.30092963203787804,\n",
       "  0.260570652782917,\n",
       "  0.21031591668725014,\n",
       "  0.18193893879652023,\n",
       "  0.23943797498941422,\n",
       "  0.28378458321094513],\n",
       " 'val_recall': [0.784, 0.872, 0.856, 0.896, 0.904, 0.92, 0.872, 0.856]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories_resnet[0].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resnet.txt\",'w') as f:\n",
    "    for history in histories_resnet:\n",
    "        print(history.history, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "histories = []\n",
    "max_length = 0\n",
    "with open(\"resnet.txt\", \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        histories.append(ast.literal_eval(line))\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.1890580232267256,\n",
       "  0.4130018817268925,\n",
       "  0.36155534984654936,\n",
       "  0.38294911746420873,\n",
       "  0.3513498618850789,\n",
       "  0.30026626635433296,\n",
       "  0.26613065613296644,\n",
       "  0.25800814178018344],\n",
       " 'recall': [0.65367967,\n",
       "  0.8095238,\n",
       "  0.8245033,\n",
       "  0.8245033,\n",
       "  0.84076434,\n",
       "  0.8741722,\n",
       "  0.88203466,\n",
       "  0.9025974],\n",
       " 'val_loss': [0.43037228286266327,\n",
       "  0.27765749394893646,\n",
       "  0.30092963203787804,\n",
       "  0.260570652782917,\n",
       "  0.21031591668725014,\n",
       "  0.18193893879652023,\n",
       "  0.23943797498941422,\n",
       "  0.28378458321094513],\n",
       " 'val_recall': [0.784, 0.872, 0.856, 0.896, 0.904, 0.92, 0.872, 0.856]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "recalls = np.array([list(v for k,v in history.items() if k.startswith('recall')) for history in histories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for recall in recalls:\n",
    "    tmp.append(recall[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[[1,2],[1,2,3],[1]]\n",
    "length = max(map(len, tmp))\n",
    "recalls=np.array([xi+[None]*(length-len(xi)) for xi in tmp])\n",
    "recalls = np.array(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for row in range(len(recalls[0])):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for item in recalls[:,row]:\n",
    "        if item != None:\n",
    "            count += 1\n",
    "            sum += item\n",
    "    means.append(sum/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.846049968,\n",
       " 0.8855276440000001,\n",
       " 0.890885168,\n",
       " 0.893910762,\n",
       " 0.8862489299999999,\n",
       " 0.90152575,\n",
       " 0.9027630099999999,\n",
       " 0.9025974]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
